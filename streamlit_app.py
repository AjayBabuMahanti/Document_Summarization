# -*- coding: utf-8 -*-
"""Lamini-LM_TextSummarization.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HzAfJXAJpNbzoabi808XRreEg4e_S8CR

**Importing Required Libraries**
"""

import streamlit as st
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.document_loaders import PyPDFLoader,DirectoryLoader
from langchain.chains.summarize import load_summarize_chain
from transformers import T5Tokenizer, T5ForConditionalGeneration
from transformers import pipeline
import torch
import base64 #Displaying PDFs, images, download links in Streamlit

"""**MODEL and TOKENIZER**"""

Checkpoint="MBZUAI/LaMini-Flan-T5-248M"
tokenizer=T5Tokenizer.from_pretrained(Checkpoint)
base_model=T5ForConditionalGeneration.from_pretrained(Checkpoint,device_map='auto',torch_dtype=torch.float32)

"""**LangChain PDF Loader**"""

def file_preprocessing(file):
  loader=PyPDFLoader(file)
  pages=loader.load_and_split()
  text_splitter=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=100)
  texts=text_splitter.split_documents(pages)
  final_texts =""
  for text in texts:
    print(text)
    final_texts+=text.page_content
  return final_texts

"""**Language Model Pipeline**"""

def llm_pipeline(filepath):
  pipe_sum=pipeline(
      "summarization",
      model=base_model,
      tokenizer=tokenizer,
      max_length=500,
      min_length=50,
      truncation=True
  )
  input_text=file_preprocessing(filepath)
  result=pipe_sum(input_text)
  return result[0]['summary_text']

from keybert import KeyBERT

kw_model = KeyBERT("sentence-transformers/all-MiniLM-L6-v2")

def llm_pipeline(filepath):
    # Load summarizer
    pipe_sum = pipeline(
        "summarization",
        model=base_model,
        tokenizer=tokenizer,
        max_length=500,
        min_length=50,
        truncation=True
    )

    input_text = file_preprocessing(filepath)

    # Smart title generation (instruction)
    title_prompt = "generate a title: " + input_text[:1000]
    title_result = pipe_sum(title_prompt, max_length=20, min_length=5, do_sample=False)
    title = title_result[0]['summary_text'].strip()

    # Summary
    result = pipe_sum(input_text)
    summary = result[0]['summary_text'].strip()

    # Keywords
    keywords = kw_model.extract_keywords(input_text, keyphrase_ngram_range=(1, 2), stop_words='english', top_n=8)
    keyword_list = [kw[0] for kw in keywords]

    return {
        "title": title,
        "summary": summary,
        "keywords": keyword_list
    }

"""Display the PDF of a given file"""

@st.cache_data
def display_pdf(file):
  # opening file from file path
  with open(file,'rb') as file:
    base64_pdf=base64.b64encode(file.read()).decode('utf-8')

  # Embedding PDF in HTML
  pdf_display=f'<iframe src="data:application/pdf;base64,{base64_pdf}" width="100%" height="600px" type="application/pdf"></iframe>'

  # Displaying File
  st.markdown(pdf_display,unsafe_allow_html=True)

"""**Streamlit Code**"""

st.set_page_config(layout='wide', page_title= "Summarization App")

def main():

  st.title('Document Summarization App using Language Model')

  uploaded_file=st.file_uploader('Upload your file',type=['pdf','docx','text'])

  if uploaded_file is not None:
    if st.button('Summarize'):
      col1, col2 = st.columns(2)
      filepath = "data/"+uploaded_file.name
      with open(filepath, 'wb) as temp_file:
                temp_file.write(uploaded_file.read())
      with col1:
        st.info('Original Text')
        pdf_viewer = displayPDF(filepath)
      with col2:
        st.info('Summarization is below')

if __name__=='__main__':
  main()
